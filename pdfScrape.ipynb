{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "combined_df=pd.DataFrame()\n",
    "directoryPath = r\"/Users/richren/Downloads/prodpages\"\n",
    "\n",
    "def extract_urls(page_source):\n",
    "            urls = re.findall(r'href=\"(.*?)\"', page_source)\n",
    "            urls = list(set([x for x in urls if (\"priip\" in x) or (\"kiid\" in x) or (\"kild\" in x) ]))\n",
    "            return urls\n",
    "\n",
    "for filename in os.listdir(directoryPath):\n",
    "    if 'klidPageSources' in filename or 'kiidPageSources' in filename:\n",
    "#         print(filename)\n",
    "        file_path=os.path.join(directoryPath,filename)\n",
    "        df=pd.read_pickle(file_path)\n",
    "        df[\"source_file\"]=filename\n",
    "        df[\"kiid\"]=df[\"pageSource\"].apply(extract_urls)\n",
    "        df=df.drop(\"pageSource\",axis=1)\n",
    "        combined_df=pd.concat([combined_df,df],ignore_index=True)\n",
    "\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_pickle(\"CombinedOut.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c225e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "combined_df=pd.read_pickle(\"CombinedOut.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da44de9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# main loop used to scrape PDF content from every identified KIID link\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "import PyPDF2\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to apply\n",
    "def pdfScrape(slices=0):\n",
    "\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    print(slices)\n",
    "\n",
    "    now = datetime.now()\n",
    "    holder = []\n",
    "\n",
    "    for index, row in (combined_df[slices]).iterrows():\n",
    "        now = datetime.now()\n",
    "        time.sleep(random.uniform(.2, 1.2))\n",
    "\n",
    "        try:\n",
    "            y = row['kiid'][0]\n",
    "            # Fetch the PDF file\n",
    "            response = requests.get(f\"https://www.blackrock.com{y}\")\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Create a PDF file object\n",
    "            pdf_file = io.BytesIO(response.content)\n",
    "\n",
    "            # Read the PDF file\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "            # Extract text from each page\n",
    "            textList = []\n",
    "            \n",
    "                    \n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text = page.extract_text()\n",
    "                textList.append(text)\n",
    "            joined = \" \".join(textList)\n",
    "            holder.append([y, joined, now])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            holder.append([row[\"url\"], \"error\", now])\n",
    "            pass\n",
    "\n",
    "    pd.DataFrame(holder).to_pickle(f'pdfScrape_{slices}.pkl')\n",
    "    print(slices, \"completed\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # batch each instance into 40 url visits\n",
    "    batches = 50\n",
    "    # calculate number of slices using batch size above\n",
    "    dfLen = combined_df.shape[0]\n",
    "    rounds = math.ceil(dfLen / batches)\n",
    "    # create slices\n",
    "    slices = [str(slice(x * batches, (x + 1) * batches)) for x in range(rounds)]\n",
    "#     print(slices)\n",
    "    # lets check the directory first to make sure we havent already created these\n",
    "    # from a previous run\n",
    "    files = os.listdir(r\"/Users/richren\")\n",
    "\n",
    "    existing = []\n",
    "    for file in files:\n",
    "        if \"pdfScrape_\" in file:\n",
    "            existing.append(file.split(\"_\")[1].split(\".\")[0])\n",
    "    # remove those slices from the list to only do new pulls\n",
    "    slices = list(set(slices) - set(existing))\n",
    "    slices = [eval(x) for x in slices]\n",
    "    print(slices)\n",
    "#     with Pool(8) as pool:\n",
    "#         df_list = pool.map(pdfScrape, slices)\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62abea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KIIDurl</th>\n",
       "      <th>kiid_text</th>\n",
       "      <th>time</th>\n",
       "      <th>SourceFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/dk/individual/literature/kiid/eu-priips-bgf-g...</td>\n",
       "      <td>1Key Information Document\\nPurpose\\nThis docum...</td>\n",
       "      <td>2024-11-23 09:30:40.004043</td>\n",
       "      <td>rr_pdfScrape_slice(5650, 5700, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/dk/individual/literature/kiid/eu-priips-bsf-g...</td>\n",
       "      <td>1Key Information Document\\nPurpose\\nThis docum...</td>\n",
       "      <td>2024-11-23 09:30:41.087057</td>\n",
       "      <td>rr_pdfScrape_slice(5650, 5700, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/dk/individual/literature/kiid/eu-priips-bgf-s...</td>\n",
       "      <td>1Key Information Document\\nPurpose\\nThis docum...</td>\n",
       "      <td>2024-11-23 09:30:43.557978</td>\n",
       "      <td>rr_pdfScrape_slice(5650, 5700, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/dk/individual/literature/kiid/eu-priips-bgf-g...</td>\n",
       "      <td>1Key Information Document\\nPurpose\\nThis docum...</td>\n",
       "      <td>2024-11-23 09:30:45.803764</td>\n",
       "      <td>rr_pdfScrape_slice(5650, 5700, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/dk/individual/literature/kiid/eu-priips-ishar...</td>\n",
       "      <td>1Key Information Document\\nPurpose\\nThis docum...</td>\n",
       "      <td>2024-11-23 09:30:48.350803</td>\n",
       "      <td>rr_pdfScrape_slice(5650, 5700, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://www.blackrock.com/de/professionelle-an...</td>\n",
       "      <td>error</td>\n",
       "      <td>2024-11-24 07:44:13.157070</td>\n",
       "      <td>rr_pdfScrape_slice(7450, 7500, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://www.blackrock.com/de/professionelle-an...</td>\n",
       "      <td>error</td>\n",
       "      <td>2024-11-24 07:44:13.656278</td>\n",
       "      <td>rr_pdfScrape_slice(7450, 7500, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://www.blackrock.com/de/professionelle-an...</td>\n",
       "      <td>error</td>\n",
       "      <td>2024-11-24 07:44:14.692619</td>\n",
       "      <td>rr_pdfScrape_slice(7450, 7500, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://www.blackrock.com/de/professionelle-an...</td>\n",
       "      <td>error</td>\n",
       "      <td>2024-11-24 07:44:15.688659</td>\n",
       "      <td>rr_pdfScrape_slice(7450, 7500, None).pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://www.blackrock.com/de/professionelle-an...</td>\n",
       "      <td>error</td>\n",
       "      <td>2024-11-24 07:44:16.073363</td>\n",
       "      <td>rr_pdfScrape_slice(7450, 7500, None).pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32136 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              KIIDurl  \\\n",
       "0   /dk/individual/literature/kiid/eu-priips-bgf-g...   \n",
       "1   /dk/individual/literature/kiid/eu-priips-bsf-g...   \n",
       "2   /dk/individual/literature/kiid/eu-priips-bgf-s...   \n",
       "3   /dk/individual/literature/kiid/eu-priips-bgf-g...   \n",
       "4   /dk/individual/literature/kiid/eu-priips-ishar...   \n",
       "..                                                ...   \n",
       "45  https://www.blackrock.com/de/professionelle-an...   \n",
       "46  https://www.blackrock.com/de/professionelle-an...   \n",
       "47  https://www.blackrock.com/de/professionelle-an...   \n",
       "48  https://www.blackrock.com/de/professionelle-an...   \n",
       "49  https://www.blackrock.com/de/professionelle-an...   \n",
       "\n",
       "                                            kiid_text  \\\n",
       "0   1Key Information Document\\nPurpose\\nThis docum...   \n",
       "1   1Key Information Document\\nPurpose\\nThis docum...   \n",
       "2   1Key Information Document\\nPurpose\\nThis docum...   \n",
       "3   1Key Information Document\\nPurpose\\nThis docum...   \n",
       "4   1Key Information Document\\nPurpose\\nThis docum...   \n",
       "..                                                ...   \n",
       "45                                              error   \n",
       "46                                              error   \n",
       "47                                              error   \n",
       "48                                              error   \n",
       "49                                              error   \n",
       "\n",
       "                         time                                SourceFile  \n",
       "0  2024-11-23 09:30:40.004043  rr_pdfScrape_slice(5650, 5700, None).pkl  \n",
       "1  2024-11-23 09:30:41.087057  rr_pdfScrape_slice(5650, 5700, None).pkl  \n",
       "2  2024-11-23 09:30:43.557978  rr_pdfScrape_slice(5650, 5700, None).pkl  \n",
       "3  2024-11-23 09:30:45.803764  rr_pdfScrape_slice(5650, 5700, None).pkl  \n",
       "4  2024-11-23 09:30:48.350803  rr_pdfScrape_slice(5650, 5700, None).pkl  \n",
       "..                        ...                                       ...  \n",
       "45 2024-11-24 07:44:13.157070  rr_pdfScrape_slice(7450, 7500, None).pkl  \n",
       "46 2024-11-24 07:44:13.656278  rr_pdfScrape_slice(7450, 7500, None).pkl  \n",
       "47 2024-11-24 07:44:14.692619  rr_pdfScrape_slice(7450, 7500, None).pkl  \n",
       "48 2024-11-24 07:44:15.688659  rr_pdfScrape_slice(7450, 7500, None).pkl  \n",
       "49 2024-11-24 07:44:16.073363  rr_pdfScrape_slice(7450, 7500, None).pkl  \n",
       "\n",
       "[32136 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "directoryPath = r\"/Users/richren\"\n",
    "\n",
    "def read_pkl_files(directory):\n",
    "    combined_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if 'pdfScrape_slice' in filename:\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                df = pd.DataFrame(data)\n",
    "                df[\"file\"] = \"rr_\"+filename\n",
    "                combined_list.append(df)\n",
    "    return pd.concat(combined_list)\n",
    "\n",
    "tempdf = read_pkl_files(directoryPath)\n",
    "tempdf\n",
    "# tempdf=pd.read_pickle(r\"/Users/richren/pdfScrape_slice(32000, 32050, None).pkl\")\n",
    "tempdf.columns=[\"KIIDurl\",\"kiid_text\",\"time\",\"SourceFile\"]\n",
    "# tempdf[\"kiidISIN\"]=tempdf[\"text\"].str.extract(r'ISIN:\\s*([^\\s]{12})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c4d4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf.to_pickle(\"scrapedPDF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"cc\"]=combined_df[\"url\"].str.split(\"/\").str[3]\n",
    "combined_df.groupby(by=\"cc\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f03b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries=[nl,se,fi,dk,no]\n",
    "import pickle\n",
    "\n",
    "directoryPath = r\"/Users/richren\"\n",
    "\n",
    "def read_pkl_files(directory):\n",
    "    combined_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if '_urls.pkl' in filename:\n",
    "            with open(os.path.join(directory, filename), 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                df = pd.DataFrame(data)\n",
    "                df[\"file\"] = filename\n",
    "                combined_list.append(df)\n",
    "    return combined_list\n",
    "\n",
    "dfList = read_pkl_files(directoryPath)\n",
    "dfList\n",
    "linkdsDF = pd.concat(dfList)\n",
    "linkdsDF.columns = [\"rootSuff\", \"country\"]\n",
    "linkdsDF[\"countryCode\"] = linkdsDF[\"country\"].str.split(\"_\").str[0]\n",
    "linkdsDF.groupby(by=\"countryCode\").count()\n",
    "# rootUrlsDF = pd.DataFrame(rootUrls)\n",
    "# rootUrlsDF.columns = [\"countryCode\", \"root\"]\n",
    "# urlsWithRoots = linkdsDF.merge(rootUrlsDF, on=\"countryCode\", how=\"left\")\n",
    "# urlsWithRoots[\"fullUrl\"] = urlsWithRoots[\"root\"] + urlsWithRoots[\"rootSuff\"]\n",
    "# urlsWithRoots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = combined_df[combined_df['kiid'].apply(len) == 0]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(filtered_df.url.tolist()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[\"prod\"]=filtered_df.url.str.split(\"/\").str[-1]\n",
    "filtered_df.groupby(\"prod\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
